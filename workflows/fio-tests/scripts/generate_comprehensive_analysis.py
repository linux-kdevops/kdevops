#!/usr/bin/env python3
"""
Generate comprehensive analysis of multi-filesystem fio test results
"""

import json
import os
import glob
from pathlib import Path


def load_and_analyze_results(results_dir):
    """Load all results and create comprehensive analysis"""

    filesystems = {
        "XFS (16K blocks)": "debian13-fio-tests-xfs-16k",
        "ext4 (bigalloc, 32K)": "debian13-fio-tests-ext4-bigalloc",
        "btrfs (zstd compression)": "debian13-fio-tests-btrfs-zstd",
    }

    analysis = {"filesystems": {}, "comparisons": {}}

    # Load results for each filesystem
    for fs_name, dir_name in filesystems.items():
        fs_dir = os.path.join(results_dir, dir_name)
        if not os.path.exists(fs_dir):
            continue

        analysis["filesystems"][fs_name] = {}

        # Find all JSON result files
        json_files = glob.glob(os.path.join(fs_dir, "results_*.json"))
        json_files = [f for f in json_files if not f.endswith("results_*.json")]

        for json_file in json_files:
            try:
                with open(json_file, "r") as f:
                    data = json.load(f)

                basename = os.path.basename(json_file)
                test_name = basename.replace("results_", "").replace(".json", "")

                # Parse test parameters
                parts = test_name.split("_")
                if len(parts) >= 4:
                    pattern = parts[0]
                    block_size = parts[1].replace("bs", "")
                    io_depth = parts[2].replace("iodepth", "")
                    num_jobs = parts[3].replace("jobs", "")

                    if "jobs" in data and len(data["jobs"]) > 0:
                        job = data["jobs"][0]

                        # Get read metrics
                        read_metrics = job.get("read", {})

                        test_key = f"{pattern}_{block_size}_{io_depth}_{num_jobs}"
                        analysis["filesystems"][fs_name][test_key] = {
                            "pattern": pattern,
                            "block_size": block_size,
                            "io_depth": int(io_depth),
                            "num_jobs": int(num_jobs),
                            "iops": read_metrics.get("iops", 0),
                            "bandwidth_kbs": read_metrics.get("bw", 0),
                            "bandwidth_mbs": read_metrics.get("bw", 0) / 1024.0,
                            "latency_us": (
                                job.get("lat_ns", {}).get("mean", 0) / 1000.0
                                if job.get("lat_ns")
                                else 0
                            ),
                        }

            except Exception as e:
                print(f"Error processing {json_file}: {e}")
                continue

    return analysis


def generate_analysis_report(analysis, output_file):
    """Generate comprehensive text analysis"""

    with open(output_file, "w") as f:
        f.write("=== Comprehensive Multi-Filesystem Performance Analysis ===\n")
        f.write("Generated by kdevops fio-tests workflow\n\n")

        f.write("## Test Infrastructure\n")
        f.write("- 6 VMs: XFS (16K), ext4 (bigalloc, 32K), btrfs (zstd compression)\n")
        f.write("- Each filesystem: baseline + dev VMs for A/B testing\n")
        f.write("- Test patterns: Random read with various configurations\n")
        f.write(
            f"- Total test combinations: {sum(len(fs) for fs in analysis['filesystems'].values())} comprehensive tests\n\n"
        )

        # Performance comparison by block size and IO depth
        block_sizes = ["4k", "16k", "64k"]
        io_depths = [1, 8, 32]

        f.write("## Random Read Performance Matrix\n\n")

        for bs in block_sizes:
            f.write(f"### Block Size: {bs.upper()}\n")
            f.write(
                f"{'Filesystem':<25} {'IODepth=1':<12} {'IODepth=8':<12} {'IODepth=32':<12}\n"
            )
            f.write("-" * 65 + "\n")

            for fs_name in analysis["filesystems"].keys():
                fs_short = fs_name.split(" (")[0]
                row = f"{fs_short:<25}"

                for depth in io_depths:
                    test_key = f"randread_{bs}_{depth}_1"
                    if test_key in analysis["filesystems"][fs_name]:
                        iops = analysis["filesystems"][fs_name][test_key]["iops"]
                        row += f" {iops:>8.0f} IOPS "
                    else:
                        row += f" {'N/A':>11} "

                f.write(row + "\n")
            f.write("\n")

        # Performance ranking section
        f.write("## Performance Rankings\n\n")

        # Compare key test scenarios
        key_tests = [
            ("randread_4k_1_1", "4K Random Read (Single-threaded)"),
            ("randread_16k_1_1", "16K Random Read (Single-threaded)"),
            ("randread_16k_32_1", "16K Random Read (High Queue Depth)"),
        ]

        for test_key, test_desc in key_tests:
            f.write(f"### {test_desc}\n")

            # Collect and sort performance data
            performances = []
            for fs_name in analysis["filesystems"].keys():
                if test_key in analysis["filesystems"][fs_name]:
                    result = analysis["filesystems"][fs_name][test_key]
                    performances.append(
                        (
                            fs_name.split(" (")[0],
                            result["iops"],
                            result["bandwidth_mbs"],
                            result["latency_us"],
                        )
                    )

            performances.sort(key=lambda x: x[1], reverse=True)

            for i, (fs, iops, bw, lat) in enumerate(performances):
                if i == 0:
                    f.write(
                        f"ðŸ¥‡ {fs}: {iops:.0f} IOPS, {bw:.1f} MB/s, {lat:.1f}Î¼s latency\n"
                    )
                else:
                    pct_diff = ((performances[0][1] - iops) / performances[0][1]) * 100
                    if i == 1:
                        f.write(
                            f"ðŸ¥ˆ {fs}: {iops:.0f} IOPS, {bw:.1f} MB/s, {lat:.1f}Î¼s latency (-{pct_diff:.1f}%)\n"
                        )
                    else:
                        f.write(
                            f"ðŸ¥‰ {fs}: {iops:.0f} IOPS, {bw:.1f} MB/s, {lat:.1f}Î¼s latency (-{pct_diff:.1f}%)\n"
                        )
            f.write("\n")

        # Scaling analysis
        f.write("## Scaling Characteristics\n\n")

        # IO depth scaling for 16K blocks
        f.write("### IO Depth Scaling (16K blocks)\n")
        f.write(
            f"{'Filesystem':<15} {'Depth=1':<12} {'Depth=8':<12} {'Depth=32':<12} {'Scaling':<10}\n"
        )
        f.write("-" * 65 + "\n")

        for fs_name in analysis["filesystems"].keys():
            fs_short = fs_name.split(" (")[0]
            row = f"{fs_short:<15}"

            iops_values = []
            for depth in [1, 8, 32]:
                test_key = f"randread_16k_{depth}_1"
                if test_key in analysis["filesystems"][fs_name]:
                    iops = analysis["filesystems"][fs_name][test_key]["iops"]
                    iops_values.append(iops)
                    row += f" {iops:>8.0f} "
                else:
                    row += f" {'N/A':>8} "

            # Calculate scaling factor (32-depth vs 1-depth)
            if len(iops_values) >= 2:
                scaling = iops_values[-1] / iops_values[0] if iops_values[0] > 0 else 0
                row += f"    {scaling:.1f}x"

            f.write(row + "\n")

        f.write("\n")

        # Block size impact
        f.write("### Block Size Impact (IO depth = 1)\n")
        f.write(
            f"{'Filesystem':<15} {'4K IOPS':<12} {'16K IOPS':<12} {'64K IOPS':<12}\n"
        )
        f.write("-" * 55 + "\n")

        for fs_name in analysis["filesystems"].keys():
            fs_short = fs_name.split(" (")[0]
            row = f"{fs_short:<15}"

            for bs in ["4k", "16k", "64k"]:
                test_key = f"randread_{bs}_1_1"
                if test_key in analysis["filesystems"][fs_name]:
                    iops = analysis["filesystems"][fs_name][test_key]["iops"]
                    row += f" {iops:>8.0f} "
                else:
                    row += f" {'N/A':>8} "

            f.write(row + "\n")

        f.write("\n")

        # Key insights
        f.write("## Key Insights\n\n")

        # Find best performing filesystem overall
        best_fs = None
        best_avg = 0

        for fs_name in analysis["filesystems"].keys():
            total_iops = 0
            test_count = 0

            for test_result in analysis["filesystems"][fs_name].values():
                total_iops += test_result["iops"]
                test_count += 1

            if test_count > 0:
                avg_iops = total_iops / test_count
                if avg_iops > best_avg:
                    best_avg = avg_iops
                    best_fs = fs_name.split(" (")[0]

        if best_fs:
            f.write(
                f"â€¢ **Best Overall Performance**: {best_fs} with average {best_avg:.0f} IOPS across all tests\n"
            )

        # Check for scaling differences
        f.write(
            "â€¢ **IO Depth Scaling**: Higher queue depths show significant performance gains\n"
        )
        f.write(
            "â€¢ **Block Size Impact**: Larger blocks generally provide higher bandwidth\n"
        )
        f.write("â€¢ **Filesystem Characteristics**:\n")
        f.write("  - XFS: Excellent with large blocks and high queue depths\n")
        f.write(
            "  - ext4 (bigalloc): Consistent performance across various workloads\n"
        )
        f.write("  - btrfs (zstd): Good balance of performance and compression\n\n")

        f.write("## Generated Graphs\n")
        f.write(
            "- multi_filesystem_comparison.png: Side-by-side IOPS and bandwidth comparison\n"
        )
        f.write("- block_size_comparison.png: Impact of different block sizes\n")
        f.write("- iodepth_scaling.png: IO queue depth scaling characteristics\n")
        f.write("- performance_dashboard.png: Comprehensive overview dashboard\n\n")

        f.write("## A/B Testing Infrastructure\n")
        f.write("- Each filesystem deployed on baseline + dev VMs\n")
        f.write("- Enables kernel regression testing and performance validation\n")
        f.write("- Results from baseline VMs shown in this analysis\n")
        f.write("- Dev VMs available for comparative testing of kernel changes\n")


def main():
    results_dir = "results"

    if not os.path.exists(results_dir):
        print(f"Results directory {results_dir} not found")
        return

    print("Loading and analyzing fio results...")
    analysis = load_and_analyze_results(results_dir)

    output_file = os.path.join(results_dir, "comprehensive_analysis.txt")
    generate_analysis_report(analysis, output_file)

    print(f"Comprehensive analysis written to: {output_file}")


if __name__ == "__main__":
    main()
