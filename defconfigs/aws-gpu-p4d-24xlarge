# AWS P4d.24xlarge GPU instance with 8x NVIDIA A100
#
# Instance specifications:
# - 8x NVIDIA A100 40GB GPUs
# - 96 vCPUs (Intel Xeon Scalable)
# - 1,152 GiB memory
# - 8x 1 TB NVMe SSD local storage
# - 400 Gbps network with EFA support
# - ~$32.77/hour on-demand pricing
#
# Ideal for large-scale ML training workloads

CONFIG_TERRAFORM=y
CONFIG_TERRAFORM_AWS=y
CONFIG_TERRAFORM_AWS_DATA_ENABLE=y
CONFIG_TERRAFORM_SSH_CONFIG_UPDATE=y
CONFIG_TERRAFORM_SSH_CONFIG_STRICT_HOST_KEY_CHECKING_ASK=y
CONFIG_TERRAFORM_SSH_CONFIG=y
CONFIG_TERRAFORM_SSH_CONFIG_BACKUP=y
CONFIG_TERRAFORM_EXTRA_VARS_AUTO=y

# Use us-east-1 for best GPU availability
CONFIG_TERRAFORM_AWS_REGION_US_EAST_1=y
CONFIG_TERRAFORM_AWS_AZ_US_EAST_1A=y

# P4d instance family with 8x A100 GPUs
CONFIG_TERRAFORM_AWS_INSTANCE_TYPE_P4D=y
CONFIG_TERRAFORM_AWS_INSTANCE_P4D_24XLARGE_CHOICE=y

# Use Deep Learning PyTorch Ubuntu AMI
CONFIG_TERRAFORM_AWS_USE_GPU_AMI=y
CONFIG_TERRAFORM_AWS_GPU_AMI_DEEP_LEARNING=y

# Use default VPC
# CONFIG_TERRAFORM_AWS_CREATE_VPC is not set
CONFIG_TERRAFORM_AWS_ASSIGN_PUBLIC_IP=y

# EBS volumes for ML datasets and checkpoints
CONFIG_TERRAFORM_AWS_EBS_VOLUMES_PER_INSTANCE=4
CONFIG_TERRAFORM_AWS_EBS_VOLUME_SIZE=100
CONFIG_TERRAFORM_AWS_EBS_VOLUME_TYPE_GP3=y

# DevOps workflow
CONFIG_WORKFLOWS_DEDICATED_WORKFLOW=y
CONFIG_KDEVOPS_WORKFLOW_ENABLE_GITR=y
CONFIG_GITR=y
CONFIG_GITR_INIT=y
CONFIG_GITR_CUSTOM_COMMAND="nvidia-smi && python -c 'import torch; print(f\"CUDA available: {torch.cuda.is_available()}, GPUs: {torch.cuda.device_count()}\")'"