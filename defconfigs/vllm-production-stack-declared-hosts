#
# vLLM Production Stack with declared hosts (bare metal with GPU)
#
# Automatically generated file; DO NOT EDIT.
# kdevops 5.0.2 Configuration
#
CONFIG_WORKFLOWS=y
CONFIG_WORKFLOWS_TESTS=y
CONFIG_WORKFLOWS_LINUX_TESTS=y
CONFIG_WORKFLOWS_DEDICATED_WORKFLOW=y
CONFIG_KDEVOPS_WORKFLOW_DEDICATE_VLLM=y

# Skip bringup for declared hosts
CONFIG_SKIP_BRINGUP=y
CONFIG_KDEVOPS_USE_DECLARED_HOSTS=y

# vLLM Production Stack with Kubernetes on declared hosts
CONFIG_VLLM_PRODUCTION_STACK=y
CONFIG_VLLM_K8S_EXISTING=y
CONFIG_VLLM_VERSION_STABLE=y
CONFIG_VLLM_ENGINE_IMAGE_TAG="v0.10.2"
CONFIG_VLLM_HELM_RELEASE_NAME="vllm-prod"
CONFIG_VLLM_HELM_NAMESPACE="vllm-system"

# Production Stack components
CONFIG_VLLM_PROD_STACK_REPO="https://vllm-project.github.io/production-stack"
CONFIG_VLLM_PROD_STACK_CHART_VERSION="latest"
CONFIG_VLLM_PROD_STACK_ROUTER_IMAGE="ghcr.io/vllm-project/production-stack/router"
CONFIG_VLLM_PROD_STACK_ROUTER_TAG="latest"
CONFIG_VLLM_PROD_STACK_ENABLE_MONITORING=y
CONFIG_VLLM_PROD_STACK_ENABLE_AUTOSCALING=y
CONFIG_VLLM_PROD_STACK_MIN_REPLICAS=2
CONFIG_VLLM_PROD_STACK_MAX_REPLICAS=5
CONFIG_VLLM_PROD_STACK_TARGET_GPU_UTILIZATION=80

# Model configuration
CONFIG_VLLM_MODEL_URL="facebook/opt-125m"
CONFIG_VLLM_MODEL_NAME="opt-125m"

# Engine configuration for GPU
CONFIG_VLLM_REPLICA_COUNT=2
CONFIG_VLLM_REQUEST_CPU=8
CONFIG_VLLM_REQUEST_MEMORY="16Gi"
CONFIG_VLLM_REQUEST_GPU=1
CONFIG_VLLM_MAX_MODEL_LEN=2048
CONFIG_VLLM_DTYPE="auto"
CONFIG_VLLM_GPU_MEMORY_UTILIZATION="0.9"
CONFIG_VLLM_TENSOR_PARALLEL_SIZE=1

# Router and observability
CONFIG_VLLM_ROUTER_ENABLED=y
CONFIG_VLLM_ROUTER_ROUND_ROBIN=y
CONFIG_VLLM_OBSERVABILITY_ENABLED=y
CONFIG_VLLM_GRAFANA_PORT=3000
CONFIG_VLLM_PROMETHEUS_PORT=9090

# API configuration
CONFIG_VLLM_API_PORT=8000
CONFIG_VLLM_API_KEY=""
CONFIG_VLLM_HF_TOKEN=""

# Benchmarking
CONFIG_VLLM_BENCHMARK_ENABLED=y
CONFIG_VLLM_BENCHMARK_DURATION=60
CONFIG_VLLM_BENCHMARK_CONCURRENT_USERS=10
CONFIG_VLLM_BENCHMARK_RESULTS_DIR="/data/vllm-benchmark"
