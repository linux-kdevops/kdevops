# Lambda Labs 8-GPU with tier-based fallback (H100 maximum tier)
# Uses 8X_H100_OR_LESS for best available 8-GPU up to H100
# Fallback order: 8x H100 → 8x A100-80 → 8x A100 → 8x V100
CONFIG_TERRAFORM=y
CONFIG_TERRAFORM_LAMBDALABS=y
CONFIG_TERRAFORM_LAMBDALABS_REGION_SMART_INFER=y
CONFIG_TERRAFORM_LAMBDALABS_INSTANCE_TYPE_8X_H100_OR_LESS=y
CONFIG_TERRAFORM_SSH_CONFIG_GENKEY=y
CONFIG_TERRAFORM_SSH_CONFIG_GENKEY_OVERWRITE=y
CONFIG_TERRAFORM_SSH_CONFIG_GENKEY_EMPTY_PASSPHRASE=y
CONFIG_WORKFLOWS=y
CONFIG_WORKFLOWS_TESTS=y
CONFIG_WORKFLOWS_LINUX_TESTS=y
CONFIG_WORKFLOWS_DEDICATED_WORKFLOW=y
