# AWS G5.xlarge GPU instance with NVIDIA A10G
#
# Instance specifications:
# - 1x NVIDIA A10G 24GB GPU
# - 4 vCPUs (AMD EPYC 7R32)
# - 16 GiB memory
# - Up to 10 Gbps network
# - ~$1.00/hour on-demand pricing
#
# Ideal for ML inference and light training workloads

CONFIG_TERRAFORM=y
CONFIG_TERRAFORM_AWS=y
CONFIG_TERRAFORM_AWS_DATA_ENABLE=y
CONFIG_TERRAFORM_SSH_CONFIG_UPDATE=y
CONFIG_TERRAFORM_SSH_CONFIG_STRICT_HOST_KEY_CHECKING_ASK=y
CONFIG_TERRAFORM_SSH_CONFIG=y
CONFIG_TERRAFORM_SSH_CONFIG_BACKUP=y
CONFIG_TERRAFORM_EXTRA_VARS_AUTO=y

# Use us-east-1 for best GPU availability
CONFIG_TERRAFORM_AWS_REGION_US_EAST_1=y
CONFIG_TERRAFORM_AWS_AZ_US_EAST_1A=y

# G5 instance family with A10G GPU
CONFIG_TERRAFORM_AWS_INSTANCE_TYPE_G5=y
CONFIG_TERRAFORM_AWS_INSTANCE_G5_XLARGE=y

# Use Deep Learning PyTorch Ubuntu AMI
CONFIG_TERRAFORM_AWS_USE_GPU_AMI=y
CONFIG_TERRAFORM_AWS_GPU_AMI_DEEP_LEARNING=y

# Use default VPC
# CONFIG_TERRAFORM_AWS_CREATE_VPC is not set
CONFIG_TERRAFORM_AWS_ASSIGN_PUBLIC_IP=y

# EBS volumes for ML datasets
CONFIG_TERRAFORM_AWS_EBS_VOLUMES_PER_INSTANCE=2
CONFIG_TERRAFORM_AWS_EBS_VOLUME_SIZE=100
CONFIG_TERRAFORM_AWS_EBS_VOLUME_TYPE_GP3=y

# DevOps workflow
CONFIG_WORKFLOWS_DEDICATED_WORKFLOW=y
CONFIG_KDEVOPS_WORKFLOW_ENABLE_GITR=y
CONFIG_GITR=y
CONFIG_GITR_INIT=y
CONFIG_GITR_CUSTOM_COMMAND="nvidia-smi && python -c 'import torch; print(torch.cuda.is_available())'"