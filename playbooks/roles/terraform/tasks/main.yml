---
- name: Check Lambda Labs API key configuration (if using Lambda Labs)
  ansible.builtin.command:
    cmd: "python3 {{ topdir_path }}/scripts/lambdalabs_credentials.py check"
  register: api_key_check
  failed_when: false
  changed_when: false
  when:
    - kdevops_terraform_provider == "lambdalabs"
  tags:
    - bringup
    - destroy
    - status

- name: Report Lambda Labs API key configuration status
  ansible.builtin.fail:
    msg: |
      ERROR: Lambda Labs API key is not configured!

      To fix this, configure your Lambda Labs API key using one of these methods:

      Use the kdevops credentials management tool:
        python3 scripts/lambdalabs_credentials.py set 'your-actual-api-key-here'

      Or manually create the credentials file:
        mkdir -p ~/.lambdalabs
        echo "[default]" > ~/.lambdalabs/credentials
        echo "lambdalabs_api_key=your-actual-api-key-here" >> ~/.lambdalabs/credentials
        chmod 600 ~/.lambdalabs/credentials

      Get your API key from: https://cloud.lambdalabs.com
  when:
    - kdevops_terraform_provider == "lambdalabs"
    - api_key_check.rc != 0
  tags:
    - bringup
    - destroy
    - status

- name: Display Lambda Labs API key configuration status
  ansible.builtin.debug:
    msg: "{{ api_key_check.stdout }}"
  when:
    - kdevops_terraform_provider == "lambdalabs"
    - api_key_check.rc == 0
  tags:
    - bringup
    - destroy
    - status

- name: Check if DataCrunch terraform provider is already installed
  ansible.builtin.stat:
    path: "~/.terraform.d/plugins/registry.terraform.io/linux-kdevops/datacrunch/0.0.3/{{ ansible_system | lower }}_{{ 'amd64' if ansible_architecture == 'x86_64' else ansible_architecture }}/terraform-provider-datacrunch_v0.0.3"
  register: datacrunch_provider_installed
  when:
    - kdevops_terraform_provider == "datacrunch"
  tags:
    - bringup
    - destroy
    - status

- name: Download and install DataCrunch terraform provider from GitHub releases
  ansible.builtin.shell:
    cmd: |
      PROVIDER_VERSION="0.0.3"
      PROVIDER_OS="{{ ansible_system | lower }}"
      PROVIDER_ARCH="{{ 'amd64' if ansible_architecture == 'x86_64' else ansible_architecture }}"
      PROVIDER_DIR="$HOME/.terraform.d/plugins/registry.terraform.io/linux-kdevops/datacrunch/${PROVIDER_VERSION}/${PROVIDER_OS}_${PROVIDER_ARCH}"

      mkdir -p "${PROVIDER_DIR}"
      cd "${PROVIDER_DIR}"

      # Download the provider binary
      wget -q "https://github.com/linux-kdevops/terraform-provider-datacrunch/releases/download/v${PROVIDER_VERSION}/terraform-provider-datacrunch_${PROVIDER_VERSION}_${PROVIDER_OS}_${PROVIDER_ARCH}.zip"

      # Extract the binary
      unzip -o "terraform-provider-datacrunch_${PROVIDER_VERSION}_${PROVIDER_OS}_${PROVIDER_ARCH}.zip"

      # Clean up zip file
      rm "terraform-provider-datacrunch_${PROVIDER_VERSION}_${PROVIDER_OS}_${PROVIDER_ARCH}.zip"

      # Make it executable
      chmod +x terraform-provider-datacrunch_v${PROVIDER_VERSION}

      echo "DataCrunch provider v${PROVIDER_VERSION} installed to ${PROVIDER_DIR}"
  when:
    - kdevops_terraform_provider == "datacrunch"
    - not datacrunch_provider_installed.stat.exists
  tags:
    - bringup
    - destroy
    - status

- name: Check Lambda Labs capacity before provisioning (if using Lambda Labs)
  ansible.builtin.shell:
    cmd: |
      {{ topdir_path }}/scripts/lambda-cli --output json check-availability \
        {{ terraform_lambdalabs_instance_type }} {{ terraform_lambdalabs_region }} | \
      python3 -c "
      import sys, json
      data = json.load(sys.stdin)
      if data.get('available'):
          print(data.get('message', 'Instance available'))
          sys.exit(0)
      else:
          print(data.get('error', 'Instance not available'))
          if 'available_regions' in data:
              print(f'  Available in: ' + ', '.join(data['available_regions']))
          sys.exit(1)
      "
  register: capacity_check
  failed_when: false
  changed_when: false
  when:
    - kdevops_terraform_provider == "lambdalabs"
  tags:
    - bringup

- name: Report Lambda Labs capacity check result
  ansible.builtin.fail:
    msg: "{{ capacity_check.stdout }}"
  when:
    - kdevops_terraform_provider == "lambdalabs"
    - capacity_check.rc != 0
  tags:
    - bringup

- name: Auto-select instance type for tier-based wildcards
  ansible.builtin.shell:
    cmd: |
      case "{{ terraform_datacrunch_instance_type }}" in
        B300_OR_LESS|B200_OR_LESS|H100_OR_LESS)
          # Use tier-based selection script
          tier_group=$(echo "{{ terraform_datacrunch_instance_type }}" | tr '[:upper:]' '[:lower:]' | tr '_' '-')
          {{ topdir_path }}/scripts/datacrunch_select_tier.py "$tier_group" --verbose
          ;;
        ANY_1H100)
          # Legacy H100 variant selection - check all regions
          for variant in 1H100.80S.30V 1H100.80S.32V; do
            result=$({{ topdir_path }}/scripts/datacrunch_check_capacity.py --instance-type "$variant" --json 2>/dev/null || echo "[]")
            location=$(echo "$result" | python3 -c "import sys, json; data=json.load(sys.stdin); print(data[0]['location']) if data and len(data) > 0 else ''" 2>/dev/null)
            if [ -n "$location" ]; then
              echo "$variant $location"
              exit 0
            fi
          done
          echo "No single H100 variants available" >&2
          exit 1
          ;;
        *)
          echo "Unknown wildcard type: {{ terraform_datacrunch_instance_type }}"
          exit 1
          ;;
      esac
  register: datacrunch_auto_instance_type
  failed_when: false
  changed_when: false
  when:
    - kdevops_terraform_provider == "datacrunch"
    - terraform_datacrunch_instance_type in ["B300_OR_LESS", "B200_OR_LESS", "H100_OR_LESS", "ANY_1H100"]
  tags:
    - bringup

- name: Fail if no instances available for wildcard selection
  ansible.builtin.fail:
    msg: |
      No GPU instances available for {{ terraform_datacrunch_instance_type }}

      {{ datacrunch_auto_instance_type.stderr }}

      Try:
        - Wait and retry (capacity changes frequently)
        - Check DataCrunch dashboard: https://cloud.datacrunch.io
        - Use a different tier group via menuconfig
        - Check capacity manually: scripts/datacrunch_check_capacity.py --instance-type <type>
  when:
    - kdevops_terraform_provider == "datacrunch"
    - terraform_datacrunch_instance_type in ["B300_OR_LESS", "B200_OR_LESS", "H100_OR_LESS", "ANY_1H100"]
    - datacrunch_auto_instance_type.rc != 0
  tags:
    - bringup

- name: Parse auto-selected instance type and location
  set_fact:
    auto_selected_instance: "{{ datacrunch_auto_instance_type.stdout.split()[0] }}"
    auto_selected_location: "{{ datacrunch_auto_instance_type.stdout.split()[1] }}"
  when:
    - kdevops_terraform_provider == "datacrunch"
    - terraform_datacrunch_instance_type in ["B300_OR_LESS", "B200_OR_LESS", "H100_OR_LESS", "ANY_1H100"]
    - datacrunch_auto_instance_type.rc == 0
  tags:
    - bringup

- name: Report auto-selected instance type for wildcards
  ansible.builtin.debug:
    msg: "Auto-selected instance type: {{ auto_selected_instance }} in region: {{ auto_selected_location }}"
  when:
    - kdevops_terraform_provider == "datacrunch"
    - terraform_datacrunch_instance_type in ["B300_OR_LESS", "B200_OR_LESS", "H100_OR_LESS", "ANY_1H100"]
    - datacrunch_auto_instance_type.rc == 0
  tags:
    - bringup

- name: Update terraform vars with auto-selected instance type
  ansible.builtin.lineinfile:
    path: "{{ topdir_path }}/terraform/{{ kdevops_terraform_provider }}/terraform.tfvars"
    regexp: '^datacrunch_instance_type\s*='
    line: 'datacrunch_instance_type = "{{ auto_selected_instance }}"'
  when:
    - kdevops_terraform_provider == "datacrunch"
    - terraform_datacrunch_instance_type in ["B300_OR_LESS", "B200_OR_LESS", "H100_OR_LESS", "ANY_1H100"]
    - datacrunch_auto_instance_type.rc == 0
  tags:
    - bringup

- name: Set resolved instance type for subsequent tasks
  set_fact:
    resolved_instance_type: "{{ auto_selected_instance if (terraform_datacrunch_instance_type in ['B300_OR_LESS', 'B200_OR_LESS', 'H100_OR_LESS', 'ANY_1H100'] and datacrunch_auto_instance_type.rc == 0) else terraform_datacrunch_instance_type }}"
  when:
    - kdevops_terraform_provider == "datacrunch"
  tags:
    - bringup

- name: Check DataCrunch capacity before provisioning (if using DataCrunch)
  ansible.builtin.shell:
    cmd: |
      {{ topdir_path }}/scripts/datacrunch_check_capacity.py \
        --instance-type {{ resolved_instance_type }} \
        --json | \
      python3 -c "
      import sys, json
      data = json.load(sys.stdin)
      if data and len(data) > 0:
          locations = [item['location'] for item in data]
          print(f'Instance {{ resolved_instance_type }} is available in: ' + ', '.join(locations))
          sys.exit(0)
      else:
          print('Error: Instance {{ resolved_instance_type }} is not available in any location')
          print('Check available instances with: scripts/datacrunch_check_capacity.py')
          sys.exit(1)
      "
  register: datacrunch_capacity_check
  failed_when: false
  changed_when: false
  when:
    - kdevops_terraform_provider == "datacrunch"
    - terraform_datacrunch_instance_type not in ["B300_OR_LESS", "B200_OR_LESS", "H100_OR_LESS", "ANY_1H100"]
  tags:
    - bringup

- name: Report DataCrunch capacity check result
  ansible.builtin.fail:
    msg: "{{ datacrunch_capacity_check.stdout }}"
  when:
    - kdevops_terraform_provider == "datacrunch"
    - datacrunch_capacity_check is defined
    - datacrunch_capacity_check.rc is defined
    - datacrunch_capacity_check.rc != 0
  tags:
    - bringup

- name: Auto-select DataCrunch location for explicit instance types
  ansible.builtin.shell:
    cmd: |
      {{ topdir_path }}/scripts/datacrunch_check_capacity.py \
        --instance-type {{ resolved_instance_type }} \
        --pick-first
  register: datacrunch_auto_location
  changed_when: false
  when:
    - kdevops_terraform_provider == "datacrunch"
    - terraform_datacrunch_instance_type not in ["B300_OR_LESS", "B200_OR_LESS", "H100_OR_LESS", "ANY_1H100"]
  tags:
    - bringup

- name: Use tier-selected location for wildcard instance types
  set_fact:
    datacrunch_final_location: "{{ auto_selected_location }}"
  when:
    - kdevops_terraform_provider == "datacrunch"
    - terraform_datacrunch_instance_type in ["B300_OR_LESS", "B200_OR_LESS", "H100_OR_LESS", "ANY_1H100"]
    - datacrunch_auto_instance_type.rc == 0
  tags:
    - bringup

- name: Use auto-selected location for explicit instance types
  set_fact:
    datacrunch_final_location: "{{ datacrunch_auto_location.stdout }}"
  when:
    - kdevops_terraform_provider == "datacrunch"
    - terraform_datacrunch_instance_type not in ["B300_OR_LESS", "B200_OR_LESS", "H100_OR_LESS", "ANY_1H100"]
    - datacrunch_auto_location.rc == 0
  tags:
    - bringup

- name: Update terraform vars with final location
  ansible.builtin.lineinfile:
    path: "{{ topdir_path }}/terraform/{{ kdevops_terraform_provider }}/terraform.tfvars"
    regexp: '^datacrunch_location\s*='
    line: 'datacrunch_location = "{{ datacrunch_final_location }}"'
  when:
    - kdevops_terraform_provider == "datacrunch"
    - datacrunch_final_location is defined
  tags:
    - bringup

- name: Display final location
  ansible.builtin.debug:
    msg: "Selected DataCrunch location: {{ datacrunch_final_location }}"
  when:
    - kdevops_terraform_provider == "datacrunch"
    - datacrunch_final_location is defined
  tags:
    - bringup

# No longer needed - terraform reads directly from credentials file

- name: Check if terraform state already has resources
  ansible.builtin.command:
    cmd: terraform state list
    chdir: "{{ topdir_path }}/terraform/{{ kdevops_terraform_provider }}"
  register: terraform_state_check
  failed_when: false
  changed_when: false
  when:
    - kdevops_terraform_provider == "datacrunch"
  tags:
    - bringup

- name: Set flag for existing terraform resources
  set_fact:
    terraform_resources_exist: "{{ terraform_state_check.stdout_lines | default([]) | length > 0 }}"
  when:
    - kdevops_terraform_provider == "datacrunch"
  tags:
    - bringup

- name: Report that infrastructure is already provisioned
  ansible.builtin.debug:
    msg: "Infrastructure already provisioned ({{ terraform_state_check.stdout_lines | default([]) | length }} resources in state). Skipping terraform apply."
  when:
    - kdevops_terraform_provider == "datacrunch"
    - terraform_resources_exist | default(false)
  tags:
    - bringup

- name: Initialize external provider for DataCrunch (workaround for dev_overrides)
  ansible.builtin.shell:
    cmd: |
      # Hide all terraform files that reference datacrunch resources
      # so that terraform init only sees the external provider requirement
      for file in provider.tf main.tf output.tf vars.tf nodes.tf; do
        if [ -f "$file" ]; then
          mv "$file" "$file.bak"
        fi
      done

      # Create minimal terraform config with only external provider
      cat > provider_init.tf << 'EOF'
      terraform {
        required_version = ">= 1.0"
        required_providers {
          external = {
            source = "hashicorp/external"
            version = "~> 2.3"
          }
        }
      }
      EOF

      # Initialize to get external provider and generate lock file
      # Suppress color output to avoid ANSI codes in logs
      terraform init -no-color > /dev/null 2>&1 || terraform init -no-color

      # Preserve the generated lock file for the external provider
      # This is needed because dev_overrides prevents normal init of datacrunch provider
      # but we still need the lock file for other providers
      if [ -f .terraform.lock.hcl ]; then
        cp .terraform.lock.hcl .terraform.lock.hcl.generated
      fi

      # Clean up temporary file and restore original terraform files
      rm provider_init.tf
      for file in provider.tf main.tf output.tf vars.tf nodes.tf; do
        if [ -f "$file.bak" ]; then
          mv "$file.bak" "$file"
        fi
      done

      # Restore the lock file after putting all files back
      if [ -f .terraform.lock.hcl.generated ]; then
        mv .terraform.lock.hcl.generated .terraform.lock.hcl
      fi
    chdir: "{{ topdir_path }}/terraform/{{ kdevops_terraform_provider }}"
  when:
    - kdevops_terraform_provider == "datacrunch"
    - not (terraform_resources_exist | default(false))
  changed_when: false
  tags:
    - bringup

- name: Bring up terraform resources (DataCrunch with dev overrides)
  ansible.builtin.command:
    cmd: terraform apply -auto-approve -no-color
    chdir: "{{ topdir_path }}/terraform/{{ kdevops_terraform_provider }}"
  when:
    - kdevops_terraform_provider == "datacrunch"
    - not (terraform_resources_exist | default(false))
  tags:
    - bringup

- name: Bring up terraform resources (other providers)
  cloud.terraform.terraform:
    force_init: true
    project_path: "{{ topdir_path }}/terraform/{{ kdevops_terraform_provider }}"
    state: present
  when:
    - kdevops_terraform_provider != "datacrunch"
  tags:
    - bringup

- name: Retrieve the controller_ip_map from terraform
  cloud.terraform.terraform_output:
    format: json
    name: controller_ip_map
    project_path: "{{ topdir_path }}/terraform/{{ kdevops_terraform_provider }}"
  register: terraform_output
  tags:
    - ssh

- name: Add each target node's ssh Host entry on the control host
  ansible.builtin.blockinfile:
    block: "{{ lookup('template', 'ssh_config.j2') }}"
    create: true
    dest: "{{ kdevops_ssh_config }}"
    insertafter: "EOF"
    marker: "# {mark} host configuration for {{ item.key }}"
    mode: "u=rw,g=r,o=r"
  loop: "{{ terraform_output.value | dict2items }}"
  tags:
    - ssh

- name: Ensure the Include directive is present on the controller
  ansible.builtin.blockinfile:
    path: "{{ sshconfig }}"
    insertbefore: BOF
    append_newline: true
    create: true
    marker: "# {mark} Managed by kdevops"
    mode: "u=rw,g=r,o=r"
    block: "Include {{ kdevops_ssh_config_prefix }}*"
  tags:
    - ssh

- name: Report terraform status
  tags:
    - status
  block:
    - name: Retrieve the controller_ip_map from terraform
      cloud.terraform.terraform_output:
        format: json
        name: controller_ip_map
        project_path: "{{ topdir_path }}/terraform/{{ kdevops_terraform_provider }}"
      register: terraform_output

    - name: End play -- terraform state file is empty or missing
      ansible.builtin.meta: end_play
      when:
        - terraform_output.warnings is defined

    - name: Count active resources
      ansible.builtin.command:
        cmd: "terraform state list"
        chdir: "{{ topdir_path }}/terraform/{{ kdevops_terraform_provider }}"
      register: terraform_state
      changed_when: false

    - name: Show status
      ansible.builtin.debug:
        msg: "Active resources: {{ terraform_state.stdout_lines | length }}"

    - name: Show controller IP map
      ansible.builtin.debug:
        var: terraform_output.value

- name: Remove the ephemeral ssh config file on the control host
  ansible.builtin.file:
    path: "{{ kdevops_ssh_config }}"
    state: absent
  tags:
    - destroy

- name: Initialize external provider for DataCrunch before destroy
  ansible.builtin.shell:
    cmd: |
      # Hide all terraform files that reference datacrunch resources
      # so that terraform init only sees the external provider requirement
      for file in provider.tf main.tf output.tf vars.tf nodes.tf; do
        if [ -f "$file" ]; then
          mv "$file" "$file.bak"
        fi
      done

      # Create minimal terraform config with only external provider
      cat > provider_init.tf << 'EOF'
      terraform {
        required_version = ">= 1.0"
        required_providers {
          external = {
            source = "hashicorp/external"
            version = "~> 2.3"
          }
        }
      }
      EOF

      # Initialize to get external provider and generate lock file
      terraform init

      # Preserve the generated lock file for the external provider
      if [ -f .terraform.lock.hcl ]; then
        cp .terraform.lock.hcl .terraform.lock.hcl.generated
      fi

      # Clean up temporary file and restore original terraform files
      rm provider_init.tf
      for file in provider.tf main.tf output.tf vars.tf nodes.tf; do
        if [ -f "$file.bak" ]; then
          mv "$file.bak" "$file"
        fi
      done

      # Restore the lock file after putting all files back
      if [ -f .terraform.lock.hcl.generated ]; then
        mv .terraform.lock.hcl.generated .terraform.lock.hcl
      fi
    chdir: "{{ topdir_path }}/terraform/{{ kdevops_terraform_provider }}"
  when:
    - kdevops_terraform_provider == "datacrunch"
  changed_when: false
  tags:
    - destroy

- name: Destroy terraform resources (DataCrunch with dev overrides)
  ansible.builtin.command:
    cmd: terraform destroy -auto-approve -no-color
    chdir: "{{ topdir_path }}/terraform/{{ kdevops_terraform_provider }}"
  when:
    - kdevops_terraform_provider == "datacrunch"
  tags:
    - destroy

- name: Remove terraform lock file for DataCrunch after destroy
  ansible.builtin.file:
    path: "{{ topdir_path }}/terraform/{{ kdevops_terraform_provider }}/.terraform.lock.hcl"
    state: absent
  when:
    - kdevops_terraform_provider == "datacrunch"
  tags:
    - destroy

- name: Destroy terraform resources (other providers)
  cloud.terraform.terraform:
    force_init: true
    project_path: "{{ topdir_path }}/terraform/{{ kdevops_terraform_provider }}"
    state: absent
  when:
    - kdevops_terraform_provider != "datacrunch"
  tags:
    - destroy
